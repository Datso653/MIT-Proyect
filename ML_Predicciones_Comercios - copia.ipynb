{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ñ Machine Learning - Predicciones Comercios Buenos Aires\n",
    "\n",
    "## MIT LIFT Lab √ó UBA - Equipo GreenThunder\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Modelos Implementados:\n",
    "\n",
    "1. **üìà Predicci√≥n de Crecimiento Comercial** - Clasificaci√≥n binaria\n",
    "2. **üè™ Score de Viabilidad/Supervivencia** - Clustering + Scoring\n",
    "3. **üí∞ Predicci√≥n de Salario Ofrecido** - Regresi√≥n\n",
    "4. **üå™Ô∏è Impacto de Factores Externos en Ventas** - Clasificaci√≥n multiclase\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è DISCLAIMER\n",
    "\n",
    "**Los modelos presentados constituyen an√°lisis estad√≠sticos predictivos basados en patrones hist√≥ricos. Estas proyecciones NO garantizan comportamiento futuro y deben interpretarse como estimaciones probabil√≠sticas sujetas a variabilidad contextual y factores externos no capturados.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ 1. Setup - Instalaci√≥n y Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librer√≠as (solo en Colab)\n",
    "# !pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    mean_squared_error, r2_score, mean_absolute_error,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Configuraci√≥n de gr√°ficos\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÇ 2. Carga de Datos\n",
    "\n",
    "**Instrucciones para Colab:**\n",
    "1. Sube el archivo `datos_comercios.csv` usando el panel de archivos (üìÅ)\n",
    "2. O m√≥ntalo desde Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opci√≥n 1: Archivo local\n",
    "df = pd.read_csv('datos_comercios.csv')\n",
    "\n",
    "# Opci√≥n 2: Desde Google Drive (descomenta si usas Drive)\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# df = pd.read_csv('/content/drive/MyDrive/datos_comercios.csv')\n",
    "\n",
    "print(f\"üìä Dataset cargado: {df.shape[0]} filas √ó {df.shape[1]} columnas\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n del dataset\n",
    "print(\"\\nüìã Informaci√≥n general:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nüìä Estad√≠sticas descriptivas:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ 3. Preprocesamiento y Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia para trabajar\n",
    "data = df.copy()\n",
    "\n",
    "# --- FEATURES DERIVADAS ---\n",
    "\n",
    "# 1. Antig√ºedad del comercio\n",
    "data['antiguedad'] = 2024 - data['a√±o_apertura']\n",
    "data['antiguedad'] = data['antiguedad'].clip(lower=0, upper=100)  # Limitar valores extremos\n",
    "\n",
    "# 2. Horas de operaci√≥n diaria\n",
    "def calcular_horas(row):\n",
    "    try:\n",
    "        apertura = int(row['hs_apertura'])\n",
    "        cierre = int(row['hs_cierre'])\n",
    "        horas = cierre - apertura\n",
    "        if horas < 0:\n",
    "            horas += 24\n",
    "        return horas\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "data['horas_operacion'] = data.apply(calcular_horas, axis=1)\n",
    "\n",
    "# 3. Tiene acceso a cr√©dito (binario)\n",
    "credito_cols = ['credits_bancos', 'credits_proveedor', 'credits_familia', 'credits_gobierno', 'credits_privado']\n",
    "data['tiene_credito'] = (data[credito_cols].sum(axis=1) > 0).astype(int)\n",
    "\n",
    "# 4. Nivel tecnol√≥gico (ordinal)\n",
    "def nivel_tech(texto):\n",
    "    if pd.isna(texto):\n",
    "        return 0\n",
    "    texto = str(texto).lower()\n",
    "    if 'alto' in texto or 'avanzado' in texto:\n",
    "        return 3\n",
    "    elif 'moderado' in texto:\n",
    "        return 2\n",
    "    elif 'b√°sico' in texto or 'basico' in texto:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['nivel_tecnologia'] = data['tecnologia'].apply(nivel_tech)\n",
    "\n",
    "# 5. Expectativas de ventas (ordinal)\n",
    "def expectativas_ventas(texto):\n",
    "    if pd.isna(texto):\n",
    "        return 0\n",
    "    texto = str(texto).lower()\n",
    "    if 'mayores' in texto or 'mejor' in texto:\n",
    "        return 1\n",
    "    elif 'menores' in texto or 'peor' in texto:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['expectativas_ventas_num'] = data['exp_ventas_3mes'].apply(expectativas_ventas)\n",
    "\n",
    "# 6. Ventas vs mes anterior (ordinal)\n",
    "def ventas_tendencia(texto):\n",
    "    if pd.isna(texto):\n",
    "        return 0\n",
    "    texto = str(texto).lower()\n",
    "    if 'mejor' in texto:\n",
    "        return 1\n",
    "    elif 'peor' in texto:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['ventas_tendencia'] = data['venta_vs_mesantes'].apply(ventas_tendencia)\n",
    "\n",
    "# 7. Local propio (binario)\n",
    "data['local_propio'] = (data['local'].str.lower() == 'propio').astype(int)\n",
    "\n",
    "# 8. Afectaciones (convertir a num√©rico)\n",
    "afect_map = {'Nada': 0, 'Poco': 1, 'Algo': 2, 'Mucho': 3}\n",
    "for col in ['afect_crimen', 'afect_credito', 'afect_precios', 'afect_compe']:\n",
    "    data[f'{col}_num'] = data[col].map(afect_map).fillna(0)\n",
    "\n",
    "# 9. Limpieza de salarios\n",
    "def limpiar_salario(val):\n",
    "    try:\n",
    "        if pd.isna(val):\n",
    "            return np.nan\n",
    "        # Remover caracteres no num√©ricos\n",
    "        cleaned = str(val).replace('$', '').replace('.', '').replace(',', '').replace(' ', '').strip()\n",
    "        num = float(cleaned)\n",
    "        # Filtrar rango razonable\n",
    "        if 100000 <= num <= 15000000:\n",
    "            return num\n",
    "        return np.nan\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "data['min_salario_clean'] = data['min_salario'].apply(limpiar_salario)\n",
    "\n",
    "print(\"‚úÖ Features creadas:\")\n",
    "print(\"   - antiguedad\")\n",
    "print(\"   - horas_operacion\")\n",
    "print(\"   - tiene_credito\")\n",
    "print(\"   - nivel_tecnologia (0-3)\")\n",
    "print(\"   - expectativas_ventas_num (-1, 0, 1)\")\n",
    "print(\"   - ventas_tendencia (-1, 0, 1)\")\n",
    "print(\"   - local_propio (0/1)\")\n",
    "print(\"   - afectaciones num√©ricas (0-3)\")\n",
    "print(\"   - min_salario_clean\")\n",
    "print(\"\\nüìä Shape despu√©s de feature engineering:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìà MODELO 1: Predicci√≥n de Crecimiento Comercial\n",
    "\n",
    "**Objetivo**: Predecir si un comercio quiere expandirse/crecer\n",
    "\n",
    "**Variable target**: `quiere_crezca` (0 = No, 1 = S√≠)\n",
    "\n",
    "**Algoritmo**: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARAR DATOS ---\n",
    "print(\"üéØ MODELO 1: Predicci√≥n de Crecimiento\\n\")\n",
    "\n",
    "# Features para el modelo\n",
    "features_m1 = [\n",
    "    'antiguedad',\n",
    "    'cantidad_trabajadores',\n",
    "    'ventas_tendencia',\n",
    "    'expectativas_ventas_num',\n",
    "    'tiene_credito',\n",
    "    'nivel_tecnologia',\n",
    "    'local_propio',\n",
    "    'horas_operacion'\n",
    "]\n",
    "\n",
    "# Preparar dataset (solo filas con target v√°lido)\n",
    "df_m1 = data[features_m1 + ['quiere_crezca']].copy()\n",
    "df_m1 = df_m1.dropna()\n",
    "df_m1 = df_m1[df_m1['quiere_crezca'].isin([0, 1, 0.0, 1.0])]\n",
    "\n",
    "X_m1 = df_m1[features_m1]\n",
    "y_m1 = df_m1['quiere_crezca'].astype(int)\n",
    "\n",
    "print(f\"üìä Tama√±o del dataset: {len(df_m1)} comercios\")\n",
    "print(f\"‚úÖ Quieren crecer: {y_m1.sum()} ({y_m1.mean()*100:.1f}%)\")\n",
    "print(f\"‚ùå No quieren crecer: {len(y_m1) - y_m1.sum()} ({(1-y_m1.mean())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAIN/TEST SPLIT ---\n",
    "X_train_m1, X_test_m1, y_train_m1, y_test_m1 = train_test_split(\n",
    "    X_m1, y_m1, test_size=0.25, random_state=42, stratify=y_m1\n",
    ")\n",
    "\n",
    "# Escalar features\n",
    "scaler_m1 = StandardScaler()\n",
    "X_train_m1_scaled = scaler_m1.fit_transform(X_train_m1)\n",
    "X_test_m1_scaled = scaler_m1.transform(X_test_m1)\n",
    "\n",
    "print(f\"üîÄ Train set: {len(X_train_m1)} | Test set: {len(X_test_m1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTRENAR MODELO ---\n",
    "print(\"\\nü§ñ Entrenando Random Forest Classifier...\\n\")\n",
    "\n",
    "rf_m1 = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_m1.fit(X_train_m1, y_train_m1)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_m1 = rf_m1.predict(X_test_m1)\n",
    "y_pred_proba_m1 = rf_m1.predict_proba(X_test_m1)[:, 1]\n",
    "\n",
    "print(\"‚úÖ Modelo entrenado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- M√âTRICAS ---\n",
    "accuracy_m1 = accuracy_score(y_test_m1, y_pred_m1)\n",
    "precision_m1 = precision_score(y_test_m1, y_pred_m1)\n",
    "recall_m1 = recall_score(y_test_m1, y_pred_m1)\n",
    "f1_m1 = f1_score(y_test_m1, y_pred_m1)\n",
    "auc_m1 = roc_auc_score(y_test_m1, y_pred_proba_m1)\n",
    "\n",
    "print(\"\\nüìä M√âTRICAS DEL MODELO 1:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"‚ö° Accuracy:  {accuracy_m1:.3f}\")\n",
    "print(f\"üéØ Precision: {precision_m1:.3f}\")\n",
    "print(f\"üìà Recall:    {recall_m1:.3f}\")\n",
    "print(f\"üî• F1-Score:  {f1_m1:.3f}\")\n",
    "print(f\"üìä AUC-ROC:   {auc_m1:.3f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test_m1, y_pred_m1, target_names=['No crece', 'S√≠ crece']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZACIONES ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('MODELO 1: Predicci√≥n de Crecimiento Comercial', fontsize=18, fontweight='bold', color='#4FC3F7')\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm_m1 = confusion_matrix(y_test_m1, y_pred_m1)\n",
    "sns.heatmap(cm_m1, annot=True, fmt='d', cmap='Blues', ax=axes[0,0], \n",
    "            xticklabels=['No crece', 'S√≠ crece'], \n",
    "            yticklabels=['No crece', 'S√≠ crece'])\n",
    "axes[0,0].set_title('Matriz de Confusi√≥n', fontsize=14, color='#4FC3F7')\n",
    "axes[0,0].set_ylabel('Real')\n",
    "axes[0,0].set_xlabel('Predicho')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_m1, y_pred_proba_m1)\n",
    "axes[0,1].plot(fpr, tpr, color='#4FC3F7', linewidth=3, label=f'AUC = {auc_m1:.3f}')\n",
    "axes[0,1].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
    "axes[0,1].set_xlabel('False Positive Rate')\n",
    "axes[0,1].set_ylabel('True Positive Rate')\n",
    "axes[0,1].set_title('ROC Curve', fontsize=14, color='#4FC3F7')\n",
    "axes[0,1].legend()\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance\n",
    "importances_m1 = pd.DataFrame({\n",
    "    'feature': features_m1,\n",
    "    'importance': rf_m1.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[1,0].barh(importances_m1['feature'], importances_m1['importance'], color='#4FC3F7')\n",
    "axes[1,0].set_xlabel('Importancia')\n",
    "axes[1,0].set_title('Feature Importance', fontsize=14, color='#4FC3F7')\n",
    "axes[1,0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Distribuci√≥n de probabilidades\n",
    "axes[1,1].hist(y_pred_proba_m1[y_test_m1 == 0], bins=30, alpha=0.6, label='No crece', color='#FF6B6B')\n",
    "axes[1,1].hist(y_pred_proba_m1[y_test_m1 == 1], bins=30, alpha=0.6, label='S√≠ crece', color='#00E676')\n",
    "axes[1,1].set_xlabel('Probabilidad predicha')\n",
    "axes[1,1].set_ylabel('Frecuencia')\n",
    "axes[1,1].set_title('Distribuci√≥n de Probabilidades', fontsize=14, color='#4FC3F7')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GUARDAR RESULTADOS MODELO 1 ---\n",
    "resultados_m1 = {\n",
    "    'modelo': 'Predicci√≥n de Crecimiento Comercial',\n",
    "    'tipo': 'clasificacion_binaria',\n",
    "    'algoritmo': 'Random Forest Classifier',\n",
    "    'metricas': {\n",
    "        'accuracy': float(accuracy_m1),\n",
    "        'precision': float(precision_m1),\n",
    "        'recall': float(recall_m1),\n",
    "        'f1_score': float(f1_m1),\n",
    "        'auc_roc': float(auc_m1)\n",
    "    },\n",
    "    'feature_importance': importances_m1.sort_values('importance', ascending=False).to_dict('records'),\n",
    "    'confusion_matrix': cm_m1.tolist(),\n",
    "    'dataset_size': {\n",
    "        'total': len(df_m1),\n",
    "        'train': len(X_train_m1),\n",
    "        'test': len(X_test_m1)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en variable 'resultados_m1'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üí∞ MODELO 2: Predicci√≥n de Salario Ofrecido\n",
    "\n",
    "**Objetivo**: Predecir el salario m√≠nimo que un comercio est√° dispuesto a pagar\n",
    "\n",
    "**Variable target**: `min_salario_clean` (continua, en ARS)\n",
    "\n",
    "**Algoritmo**: Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARAR DATOS ---\n",
    "print(\"üí∞ MODELO 2: Predicci√≥n de Salario\\n\")\n",
    "\n",
    "features_m2 = [\n",
    "    'antiguedad',\n",
    "    'cantidad_trabajadores',\n",
    "    'ventas_tendencia',\n",
    "    'nivel_tecnologia',\n",
    "    'local_propio',\n",
    "    'horas_operacion',\n",
    "    'tiene_credito'\n",
    "]\n",
    "\n",
    "# Preparar dataset\n",
    "df_m2 = data[features_m2 + ['min_salario_clean', 'tipo_comercio']].copy()\n",
    "df_m2 = df_m2.dropna(subset=['min_salario_clean'])\n",
    "df_m2 = df_m2.dropna(subset=features_m2)\n",
    "\n",
    "# One-hot encoding para tipo_comercio\n",
    "tipo_dummies = pd.get_dummies(df_m2['tipo_comercio'], prefix='tipo')\n",
    "X_m2 = pd.concat([df_m2[features_m2], tipo_dummies], axis=1)\n",
    "y_m2 = df_m2['min_salario_clean']\n",
    "\n",
    "print(f\"üìä Tama√±o del dataset: {len(df_m2)} comercios\")\n",
    "print(f\"üíµ Salario promedio: ${y_m2.mean():,.0f} ARS\")\n",
    "print(f\"üíµ Salario mediana: ${y_m2.median():,.0f} ARS\")\n",
    "print(f\"üíµ Rango: ${y_m2.min():,.0f} - ${y_m2.max():,.0f} ARS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAIN/TEST SPLIT ---\n",
    "X_train_m2, X_test_m2, y_train_m2, y_test_m2 = train_test_split(\n",
    "    X_m2, y_m2, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"üîÄ Train set: {len(X_train_m2)} | Test set: {len(X_test_m2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTRENAR MODELO ---\n",
    "print(\"\\nü§ñ Entrenando Gradient Boosting Regressor...\\n\")\n",
    "\n",
    "gbr_m2 = GradientBoostingRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gbr_m2.fit(X_train_m2, y_train_m2)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_m2 = gbr_m2.predict(X_test_m2)\n",
    "\n",
    "print(\"‚úÖ Modelo entrenado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- M√âTRICAS ---\n",
    "r2_m2 = r2_score(y_test_m2, y_pred_m2)\n",
    "rmse_m2 = np.sqrt(mean_squared_error(y_test_m2, y_pred_m2))\n",
    "mae_m2 = mean_absolute_error(y_test_m2, y_pred_m2)\n",
    "mape_m2 = np.mean(np.abs((y_test_m2 - y_pred_m2) / y_test_m2)) * 100\n",
    "\n",
    "print(\"\\nüìä M√âTRICAS DEL MODELO 2:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìà R¬≤ Score:  {r2_m2:.3f}\")\n",
    "print(f\"üìâ RMSE:      ${rmse_m2:,.0f} ARS\")\n",
    "print(f\"üìä MAE:       ${mae_m2:,.0f} ARS\")\n",
    "print(f\"üìê MAPE:      {mape_m2:.2f}%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZACIONES ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('MODELO 2: Predicci√≥n de Salario Ofrecido', fontsize=18, fontweight='bold', color='#4FC3F7')\n",
    "\n",
    "# 1. Predicci√≥n vs Real\n",
    "axes[0,0].scatter(y_test_m2, y_pred_m2, alpha=0.5, color='#4FC3F7')\n",
    "axes[0,0].plot([y_test_m2.min(), y_test_m2.max()], \n",
    "               [y_test_m2.min(), y_test_m2.max()], \n",
    "               'r--', linewidth=2, label='Ideal')\n",
    "axes[0,0].set_xlabel('Salario Real (ARS)')\n",
    "axes[0,0].set_ylabel('Salario Predicho (ARS)')\n",
    "axes[0,0].set_title(f'Predicci√≥n vs Real (R¬≤ = {r2_m2:.3f})', fontsize=14, color='#4FC3F7')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Residuos\n",
    "residuos_m2 = y_test_m2 - y_pred_m2\n",
    "axes[0,1].scatter(y_pred_m2, residuos_m2, alpha=0.5, color='#4FC3F7')\n",
    "axes[0,1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[0,1].set_xlabel('Predicci√≥n (ARS)')\n",
    "axes[0,1].set_ylabel('Residuo (ARS)')\n",
    "axes[0,1].set_title('Gr√°fico de Residuos', fontsize=14, color='#4FC3F7')\n",
    "axes[0,1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Feature Importance\n",
    "importances_m2 = pd.DataFrame({\n",
    "    'feature': X_m2.columns,\n",
    "    'importance': gbr_m2.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[1,0].barh(range(len(importances_m2)), importances_m2['importance'], color='#4FC3F7')\n",
    "axes[1,0].set_yticks(range(len(importances_m2)))\n",
    "axes[1,0].set_yticklabels(importances_m2['feature'])\n",
    "axes[1,0].set_xlabel('Importancia')\n",
    "axes[1,0].set_title('Top 15 Features M√°s Importantes', fontsize=14, color='#4FC3F7')\n",
    "axes[1,0].invert_yaxis()\n",
    "axes[1,0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Distribuci√≥n de errores\n",
    "axes[1,1].hist(residuos_m2, bins=30, color='#4FC3F7', edgecolor='black', alpha=0.7)\n",
    "axes[1,1].axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "axes[1,1].set_xlabel('Error (ARS)')\n",
    "axes[1,1].set_ylabel('Frecuencia')\n",
    "axes[1,1].set_title('Distribuci√≥n de Errores', fontsize=14, color='#4FC3F7')\n",
    "axes[1,1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GUARDAR RESULTADOS MODELO 2 ---\n",
    "resultados_m2 = {\n",
    "    'modelo': 'Predicci√≥n de Salario Ofrecido',\n",
    "    'tipo': 'regresion',\n",
    "    'algoritmo': 'Gradient Boosting Regressor',\n",
    "    'metricas': {\n",
    "        'r2_score': float(r2_m2),\n",
    "        'rmse': float(rmse_m2),\n",
    "        'mae': float(mae_m2),\n",
    "        'mape': float(mape_m2)\n",
    "    },\n",
    "    'feature_importance': importances_m2.to_dict('records'),\n",
    "    'estadisticas_salario': {\n",
    "        'promedio': float(y_m2.mean()),\n",
    "        'mediana': float(y_m2.median()),\n",
    "        'min': float(y_m2.min()),\n",
    "        'max': float(y_m2.max())\n",
    "    },\n",
    "    'dataset_size': {\n",
    "        'total': len(df_m2),\n",
    "        'train': len(X_train_m2),\n",
    "        'test': len(X_test_m2)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en variable 'resultados_m2'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üå™Ô∏è MODELO 3: Impacto de Factores Externos en Ventas\n",
    "\n",
    "**Objetivo**: Predecir tendencia de ventas seg√∫n factores externos\n",
    "\n",
    "**Variable target**: `ventas_tendencia` (-1=Peor, 0=Igual, 1=Mejor)\n",
    "\n",
    "**Algoritmo**: Random Forest Classifier (multiclase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARAR DATOS ---\n",
    "print(\"üå™Ô∏è MODELO 3: Impacto de Factores Externos\\n\")\n",
    "\n",
    "features_m3 = [\n",
    "    'afect_crimen_num',\n",
    "    'afect_credito_num',\n",
    "    'afect_precios_num',\n",
    "    'afect_compe_num',\n",
    "    'nivel_tecnologia',\n",
    "    'antiguedad',\n",
    "    'cantidad_trabajadores',\n",
    "    'tiene_credito'\n",
    "]\n",
    "\n",
    "# Preparar dataset\n",
    "df_m3 = data[features_m3 + ['ventas_tendencia', 'tipo_comercio']].copy()\n",
    "df_m3 = df_m3.dropna()\n",
    "\n",
    "# One-hot encoding\n",
    "tipo_dummies_m3 = pd.get_dummies(df_m3['tipo_comercio'], prefix='tipo')\n",
    "X_m3 = pd.concat([df_m3[features_m3], tipo_dummies_m3], axis=1)\n",
    "y_m3 = df_m3['ventas_tendencia']\n",
    "\n",
    "print(f\"üìä Tama√±o del dataset: {len(df_m3)} comercios\")\n",
    "print(f\"\\nDistribuci√≥n de clases:\")\n",
    "print(y_m3.value_counts().sort_index())\n",
    "print(f\"\\nüìà Mejor:  {(y_m3 == 1).sum()} ({(y_m3 == 1).mean()*100:.1f}%)\")\n",
    "print(f\"‚û°Ô∏è  Igual:  {(y_m3 == 0).sum()} ({(y_m3 == 0).mean()*100:.1f}%)\")\n",
    "print(f\"üìâ Peor:   {(y_m3 == -1).sum()} ({(y_m3 == -1).mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TRAIN/TEST SPLIT ---\n",
    "X_train_m3, X_test_m3, y_train_m3, y_test_m3 = train_test_split(\n",
    "    X_m3, y_m3, test_size=0.25, random_state=42, stratify=y_m3\n",
    ")\n",
    "\n",
    "print(f\"üîÄ Train set: {len(X_train_m3)} | Test set: {len(X_test_m3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ENTRENAR MODELO ---\n",
    "print(\"\\nü§ñ Entrenando Random Forest Classifier (Multiclase)...\\n\")\n",
    "\n",
    "rf_m3 = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_m3.fit(X_train_m3, y_train_m3)\n",
    "\n",
    "# Predicciones\n",
    "y_pred_m3 = rf_m3.predict(X_test_m3)\n",
    "\n",
    "print(\"‚úÖ Modelo entrenado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- M√âTRICAS ---\n",
    "accuracy_m3 = accuracy_score(y_test_m3, y_pred_m3)\n",
    "f1_weighted_m3 = f1_score(y_test_m3, y_pred_m3, average='weighted')\n",
    "\n",
    "print(\"\\nüìä M√âTRICAS DEL MODELO 3:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"‚ö° Accuracy:        {accuracy_m3:.3f}\")\n",
    "print(f\"üî• F1-Score (Weighted): {f1_weighted_m3:.3f}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìã Classification Report:\")\n",
    "print(classification_report(y_test_m3, y_pred_m3, \n",
    "                          target_names=['Peor', 'Igual', 'Mejor']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZACIONES ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('MODELO 3: Impacto de Factores Externos en Ventas', \n",
    "             fontsize=18, fontweight='bold', color='#4FC3F7')\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm_m3 = confusion_matrix(y_test_m3, y_pred_m3)\n",
    "sns.heatmap(cm_m3, annot=True, fmt='d', cmap='Blues', ax=axes[0,0],\n",
    "            xticklabels=['Peor', 'Igual', 'Mejor'],\n",
    "            yticklabels=['Peor', 'Igual', 'Mejor'])\n",
    "axes[0,0].set_title('Matriz de Confusi√≥n', fontsize=14, color='#4FC3F7')\n",
    "axes[0,0].set_ylabel('Real')\n",
    "axes[0,0].set_xlabel('Predicho')\n",
    "\n",
    "# 2. Feature Importance\n",
    "importances_m3 = pd.DataFrame({\n",
    "    'feature': X_m3.columns,\n",
    "    'importance': rf_m3.feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[0,1].barh(range(len(importances_m3)), importances_m3['importance'], color='#4FC3F7')\n",
    "axes[0,1].set_yticks(range(len(importances_m3)))\n",
    "axes[0,1].set_yticklabels(importances_m3['feature'])\n",
    "axes[0,1].set_xlabel('Importancia')\n",
    "axes[0,1].set_title('Top 15 Features M√°s Importantes', fontsize=14, color='#4FC3F7')\n",
    "axes[0,1].invert_yaxis()\n",
    "axes[0,1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Distribuci√≥n de predicciones\n",
    "pred_counts = pd.Series(y_pred_m3).value_counts().sort_index()\n",
    "axes[1,0].bar(['Peor', 'Igual', 'Mejor'], pred_counts.values, color='#4FC3F7')\n",
    "axes[1,0].set_ylabel('Cantidad')\n",
    "axes[1,0].set_title('Distribuci√≥n de Predicciones', fontsize=14, color='#4FC3F7')\n",
    "axes[1,0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Impacto promedio de afectaciones\n",
    "afectaciones = ['afect_crimen_num', 'afect_credito_num', 'afect_precios_num', 'afect_compe_num']\n",
    "impacto_promedio = df_m3.groupby('ventas_tendencia')[afectaciones].mean()\n",
    "\n",
    "x_pos = np.arange(len(afectaciones))\n",
    "width = 0.25\n",
    "\n",
    "axes[1,1].bar(x_pos - width, impacto_promedio.loc[-1], width, label='Peor', color='#FF6B6B')\n",
    "axes[1,1].bar(x_pos, impacto_promedio.loc[0], width, label='Igual', color='#FFB74D')\n",
    "axes[1,1].bar(x_pos + width, impacto_promedio.loc[1], width, label='Mejor', color='#00E676')\n",
    "\n",
    "axes[1,1].set_xticks(x_pos)\n",
    "axes[1,1].set_xticklabels(['Crimen', 'Cr√©dito', 'Precios', 'Competencia'], rotation=45)\n",
    "axes[1,1].set_ylabel('Nivel de Afectaci√≥n Promedio (0-3)')\n",
    "axes[1,1].set_title('Afectaciones por Tendencia de Ventas', fontsize=14, color='#4FC3F7')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GUARDAR RESULTADOS MODELO 3 ---\n",
    "resultados_m3 = {\n",
    "    'modelo': 'Impacto de Factores Externos en Ventas',\n",
    "    'tipo': 'clasificacion_multiclase',\n",
    "    'algoritmo': 'Random Forest Classifier',\n",
    "    'metricas': {\n",
    "        'accuracy': float(accuracy_m3),\n",
    "        'f1_weighted': float(f1_weighted_m3)\n",
    "    },\n",
    "    'feature_importance': importances_m3.to_dict('records'),\n",
    "    'confusion_matrix': cm_m3.tolist(),\n",
    "    'distribucion_clases': y_m3.value_counts().sort_index().to_dict(),\n",
    "    'dataset_size': {\n",
    "        'total': len(df_m3),\n",
    "        'train': len(X_train_m3),\n",
    "        'test': len(X_test_m3)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en variable 'resultados_m3'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üè™ MODELO 4: Score de Viabilidad Comercial\n",
    "\n",
    "**Objetivo**: Agrupar comercios seg√∫n su salud/viabilidad usando clustering\n",
    "\n",
    "**M√©todo**: K-Means Clustering + Score compuesto\n",
    "\n",
    "**Dimensiones del score**: Expectativas, Cr√©dito, Inventario, Antig√ºedad, Trabajadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PREPARAR DATOS ---\n",
    "print(\"üè™ MODELO 4: Score de Viabilidad\\n\")\n",
    "\n",
    "features_m4 = [\n",
    "    'expectativas_ventas_num',\n",
    "    'tiene_credito',\n",
    "    'nivel_tecnologia',\n",
    "    'antiguedad',\n",
    "    'cantidad_trabajadores',\n",
    "    'horas_operacion',\n",
    "    'local_propio'\n",
    "]\n",
    "\n",
    "# Preparar dataset\n",
    "df_m4 = data[features_m4].copy()\n",
    "df_m4 = df_m4.dropna()\n",
    "\n",
    "print(f\"üìä Tama√±o del dataset: {len(df_m4)} comercios\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NORMALIZAR ---\n",
    "scaler_m4 = StandardScaler()\n",
    "X_m4_scaled = scaler_m4.fit_transform(df_m4)\n",
    "\n",
    "print(\"‚úÖ Datos normalizados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CLUSTERING K-MEANS ---\n",
    "print(\"\\nü§ñ Aplicando K-Means (k=3)...\\n\")\n",
    "\n",
    "kmeans_m4 = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "clusters_m4 = kmeans_m4.fit_predict(X_m4_scaled)\n",
    "\n",
    "df_m4['cluster'] = clusters_m4\n",
    "\n",
    "print(\"‚úÖ Clustering completado!\")\n",
    "print(f\"\\nDistribuci√≥n de clusters:\")\n",
    "print(pd.Series(clusters_m4).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CALCULAR SCORE DE VIABILIDAD ---\n",
    "\n",
    "def calcular_score(row):\n",
    "    score = 0\n",
    "    \n",
    "    # Expectativas positivas (0-30 puntos)\n",
    "    if row['expectativas_ventas_num'] == 1:\n",
    "        score += 30\n",
    "    elif row['expectativas_ventas_num'] == 0:\n",
    "        score += 15\n",
    "    \n",
    "    # Acceso a cr√©dito (0-20 puntos)\n",
    "    if row['tiene_credito'] == 1:\n",
    "        score += 20\n",
    "    \n",
    "    # Tecnolog√≠a (0-20 puntos)\n",
    "    score += (row['nivel_tecnologia'] / 3) * 20\n",
    "    \n",
    "    # Antig√ºedad (0-15 puntos) - m√°s antig√ºedad = m√°s estable\n",
    "    antiguedad_norm = min(row['antiguedad'] / 20, 1)  # Cap a 20 a√±os\n",
    "    score += antiguedad_norm * 15\n",
    "    \n",
    "    # Trabajadores (0-10 puntos)\n",
    "    trabajadores_norm = min(row['cantidad_trabajadores'] / 10, 1)\n",
    "    score += trabajadores_norm * 10\n",
    "    \n",
    "    # Local propio (0-5 puntos)\n",
    "    if row['local_propio'] == 1:\n",
    "        score += 5\n",
    "    \n",
    "    return round(score, 1)\n",
    "\n",
    "df_m4['score_viabilidad'] = df_m4.apply(calcular_score, axis=1)\n",
    "\n",
    "print(\"üìä Score de Viabilidad calculado\")\n",
    "print(f\"\\nEstad√≠sticas del score:\")\n",
    "print(df_m4['score_viabilidad'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ETIQUETAR CLUSTERS ---\n",
    "# Ordenar clusters por score promedio\n",
    "cluster_scores = df_m4.groupby('cluster')['score_viabilidad'].mean().sort_values(ascending=False)\n",
    "cluster_labels = {cluster_scores.index[0]: 'Alto', \n",
    "                 cluster_scores.index[1]: 'Medio', \n",
    "                 cluster_scores.index[2]: 'Bajo'}\n",
    "\n",
    "df_m4['nivel_viabilidad'] = df_m4['cluster'].map(cluster_labels)\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Clusters etiquetados:\")\n",
    "print(df_m4['nivel_viabilidad'].value_counts())\n",
    "\n",
    "print(\"\\nüìä Score promedio por nivel:\")\n",
    "print(df_m4.groupby('nivel_viabilidad')['score_viabilidad'].mean().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VISUALIZACIONES ---\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "fig.suptitle('MODELO 4: Score de Viabilidad Comercial', \n",
    "             fontsize=18, fontweight='bold', color='#4FC3F7')\n",
    "\n",
    "# 1. PCA 2D de clusters\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "pca_m4 = PCA(n_components=2)\n",
    "X_pca_m4 = pca_m4.fit_transform(X_m4_scaled)\n",
    "df_pca = pd.DataFrame(X_pca_m4, columns=['PC1', 'PC2'])\n",
    "df_pca['cluster'] = df_m4['nivel_viabilidad'].values\n",
    "\n",
    "colors = {'Alto': '#00E676', 'Medio': '#4FC3F7', 'Bajo': '#FF6B6B'}\n",
    "for nivel in ['Alto', 'Medio', 'Bajo']:\n",
    "    mask = df_pca['cluster'] == nivel\n",
    "    ax1.scatter(df_pca[mask]['PC1'], df_pca[mask]['PC2'], \n",
    "               label=nivel, alpha=0.6, s=100, color=colors[nivel])\n",
    "\n",
    "ax1.set_xlabel(f'PC1 ({pca_m4.explained_variance_ratio_[0]*100:.1f}% var)')\n",
    "ax1.set_ylabel(f'PC2 ({pca_m4.explained_variance_ratio_[1]*100:.1f}% var)')\n",
    "ax1.set_title('Visualizaci√≥n PCA de Clusters', fontsize=14, color='#4FC3F7')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# 2. Distribuci√≥n de scores por cluster\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "for nivel in ['Alto', 'Medio', 'Bajo']:\n",
    "    data_nivel = df_m4[df_m4['nivel_viabilidad'] == nivel]['score_viabilidad']\n",
    "    ax2.hist(data_nivel, bins=20, alpha=0.6, label=nivel, color=colors[nivel])\n",
    "ax2.set_xlabel('Score de Viabilidad')\n",
    "ax2.set_ylabel('Frecuencia')\n",
    "ax2.set_title('Distribuci√≥n de Scores', fontsize=14, color='#4FC3F7')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 3. Boxplot de scores\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "df_m4.boxplot(column='score_viabilidad', by='nivel_viabilidad', ax=ax3)\n",
    "ax3.set_xlabel('Nivel de Viabilidad')\n",
    "ax3.set_ylabel('Score')\n",
    "ax3.set_title('Comparaci√≥n de Scores', fontsize=14, color='#4FC3F7')\n",
    "plt.sca(ax3)\n",
    "plt.xticks([1, 2, 3], ['Alto', 'Medio', 'Bajo'])\n",
    "\n",
    "# 4. Conteo por cluster\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "counts = df_m4['nivel_viabilidad'].value_counts()\n",
    "ax4.bar(['Alto', 'Medio', 'Bajo'], \n",
    "        [counts.get('Alto', 0), counts.get('Medio', 0), counts.get('Bajo', 0)],\n",
    "        color=[colors['Alto'], colors['Medio'], colors['Bajo']])\n",
    "ax4.set_ylabel('Cantidad de Comercios')\n",
    "ax4.set_title('Distribuci√≥n por Nivel', fontsize=14, color='#4FC3F7')\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Radar chart de caracter√≠sticas por cluster\n",
    "ax5 = fig.add_subplot(gs[2, :], projection='polar')\n",
    "\n",
    "# Promedios por cluster (normalizados 0-1)\n",
    "features_radar = ['expectativas_ventas_num', 'tiene_credito', 'nivel_tecnologia', \n",
    "                 'antiguedad', 'cantidad_trabajadores']\n",
    "\n",
    "for nivel in ['Alto', 'Medio', 'Bajo']:\n",
    "    valores = df_m4[df_m4['nivel_viabilidad'] == nivel][features_radar].mean()\n",
    "    # Normalizar entre 0 y 1\n",
    "    valores_norm = (valores - valores.min()) / (valores.max() - valores.min() + 0.001)\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(features_radar), endpoint=False).tolist()\n",
    "    valores_norm = valores_norm.tolist()\n",
    "    valores_norm += valores_norm[:1]\n",
    "    angles += angles[:1]\n",
    "    \n",
    "    ax5.plot(angles, valores_norm, 'o-', linewidth=2, label=nivel, color=colors[nivel])\n",
    "    ax5.fill(angles, valores_norm, alpha=0.15, color=colors[nivel])\n",
    "\n",
    "ax5.set_xticks(angles[:-1])\n",
    "ax5.set_xticklabels(['Expectativas', 'Cr√©dito', 'Tecnolog√≠a', 'Antig√ºedad', 'Trabajadores'])\n",
    "ax5.set_ylim(0, 1)\n",
    "ax5.set_title('Perfil de Caracter√≠sticas por Nivel', fontsize=14, color='#4FC3F7', pad=20)\n",
    "ax5.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "ax5.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GUARDAR RESULTADOS MODELO 4 ---\n",
    "resultados_m4 = {\n",
    "    'modelo': 'Score de Viabilidad Comercial',\n",
    "    'tipo': 'clustering',\n",
    "    'algoritmo': 'K-Means (k=3)',\n",
    "    'distribucion_clusters': df_m4['nivel_viabilidad'].value_counts().to_dict(),\n",
    "    'score_promedio_por_nivel': df_m4.groupby('nivel_viabilidad')['score_viabilidad'].mean().to_dict(),\n",
    "    'estadisticas_score': {\n",
    "        'min': float(df_m4['score_viabilidad'].min()),\n",
    "        'max': float(df_m4['score_viabilidad'].max()),\n",
    "        'mean': float(df_m4['score_viabilidad'].mean()),\n",
    "        'median': float(df_m4['score_viabilidad'].median())\n",
    "    },\n",
    "    'varianza_explicada_pca': {\n",
    "        'PC1': float(pca_m4.explained_variance_ratio_[0]),\n",
    "        'PC2': float(pca_m4.explained_variance_ratio_[1])\n",
    "    },\n",
    "    'dataset_size': len(df_m4)\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Resultados guardados en variable 'resultados_m4'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üíæ EXPORTAR RESULTADOS PARA LA WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONSOLIDAR TODOS LOS RESULTADOS ---\n",
    "resultados_completos = {\n",
    "    'metadata': {\n",
    "        'fecha_analisis': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'dataset_original': {\n",
    "            'filas': len(df),\n",
    "            'columnas': len(df.columns)\n",
    "        },\n",
    "        'equipo': 'GreenThunder',\n",
    "        'institucion': 'MIT LIFT Lab √ó UBA'\n",
    "    },\n",
    "    'modelos': {\n",
    "        'modelo_1_crecimiento': resultados_m1,\n",
    "        'modelo_2_salario': resultados_m2,\n",
    "        'modelo_3_factores_externos': resultados_m3,\n",
    "        'modelo_4_viabilidad': resultados_m4\n",
    "    }\n",
    "}\n",
    "\n",
    "# Guardar JSON\n",
    "with open('ml_results.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(resultados_completos, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"\\n‚úÖ RESULTADOS EXPORTADOS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìÅ Archivo: ml_results.json\")\n",
    "print(f\"üìä Tama√±o: {len(json.dumps(resultados_completos))/1024:.1f} KB\")\n",
    "print(\"\\nüéØ Listo para integrar en la web!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä RESUMEN FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ RESUMEN DE MODELOS - MACHINE LEARNING COMERCIOS\".center(70))\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"üìà MODELO 1: Predicci√≥n de Crecimiento Comercial\")\n",
    "print(f\"   ‚Ä¢ Accuracy:  {accuracy_m1:.3f}\")\n",
    "print(f\"   ‚Ä¢ AUC-ROC:   {auc_m1:.3f}\")\n",
    "print(f\"   ‚Ä¢ Dataset:   {len(df_m1)} comercios\\n\")\n",
    "\n",
    "print(\"üí∞ MODELO 2: Predicci√≥n de Salario Ofrecido\")\n",
    "print(f\"   ‚Ä¢ R¬≤ Score:  {r2_m2:.3f}\")\n",
    "print(f\"   ‚Ä¢ RMSE:      ${rmse_m2:,.0f} ARS\")\n",
    "print(f\"   ‚Ä¢ MAPE:      {mape_m2:.2f}%\")\n",
    "print(f\"   ‚Ä¢ Dataset:   {len(df_m2)} comercios\\n\")\n",
    "\n",
    "print(\"üå™Ô∏è MODELO 3: Impacto de Factores Externos\")\n",
    "print(f\"   ‚Ä¢ Accuracy:  {accuracy_m3:.3f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {f1_weighted_m3:.3f}\")\n",
    "print(f\"   ‚Ä¢ Dataset:   {len(df_m3)} comercios\\n\")\n",
    "\n",
    "print(\"üè™ MODELO 4: Score de Viabilidad\")\n",
    "print(f\"   ‚Ä¢ Clusters:  3 niveles (Alto/Medio/Bajo)\")\n",
    "print(f\"   ‚Ä¢ Score promedio: {df_m4['score_viabilidad'].mean():.1f}/100\")\n",
    "print(f\"   ‚Ä¢ Dataset:   {len(df_m4)} comercios\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚úÖ AN√ÅLISIS COMPLETADO\".center(70))\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
